{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x1113eb358>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.parquet(\"tweets.consolidated.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------------------+--------------------+--------+\n",
      "|      user|                id|                text|            location|hasMedia|\n",
      "+----------+------------------+--------------------+--------------------+--------+\n",
      "| 429803867|668129332066459648|e0b40f2381c430f6d...|[27.166142,73.852...|   false|\n",
      "|2575662781|668129436932415488|:) https://t.co/r...|[19.5371016,-96.9...|    true|\n",
      "|2558754024|668128681945092096|برد 😊 (@ miral -...|[29.10425394,48.1...|   false|\n",
      "| 175196235|668128627406610432|christmas market:...|[43.6506691,-79.3...|   false|\n",
      "| 737480838|668128627394019328|يا عزيزي يالمدريد...|[26.21390031,50.4...|   false|\n",
      "|  22921151|668129030068166657|#noelgeek #ghostb...|[45.50757496,-73....|   false|\n",
      "|  93448793|668129332041265152|Soooooo these #ne...|[38.72750195,-90....|   false|\n",
      "| 959736212|668128937801682945|Green Turtle in W...|[39.5640488,-76.9...|   false|\n",
      "|  59972446|668129025890455552|#Retail #Job in #...|[41.4517093,-82.0...|   false|\n",
      "|3234610719|668129269160222720|#StaracArabia\n",
      "الن...|[30.0960606,31.33...|   false|\n",
      "|2329037172|668128677763379201|Açlık oyunları al...|[38.33868221,27.1...|   false|\n",
      "|  86583009|668128749032902656|#beaurivagegolf #...|[34.11432705,-77....|   false|\n",
      "| 569410380|668129231386333185|@bm0406 @ionacrv ...|[19.09500403,72.8...|   false|\n",
      "|2781520319|668129369819357184|#Bilinmezlik @ İz...|[38.29360749,27.1...|   false|\n",
      "| 110213197|668128673560592384|Razón tenía aquel...|[9.91077394,-84.0...|   false|\n",
      "|1179981192|668129055238062081|349.336 personas ...|   [40.4203,-3.7058]|   false|\n",
      "| 156122032|668128820365512704|🎉🎉🎉 @ Quilmes,...| [-34.7203,-58.2694]|   false|\n",
      "|  27737029|668129436898885633|Risottinho de moq...|[-22.97027778,-43...|   false|\n",
      "| 245111438|668128317044826113|fish bowl fridays...|[42.09727335,-75....|   false|\n",
      "| 543604821|668128518354698242|Viendo el partido...|[19.39476248,-99....|   false|\n",
      "+----------+------------------+--------------------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: long (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- location: struct (nullable = true)\n",
      " |    |-- latitude: double (nullable = true)\n",
      " |    |-- longitude: double (nullable = true)\n",
      " |-- hasMedia: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|hasMedia|count|\n",
      "+--------+-----+\n",
      "|    true|  118|\n",
      "|   false| 1967|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"hasMedia\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def boolToInt(val):\n",
    "    if val:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "ml_df = sqlContext.createDataFrame(df.map(lambda r : Row(id=r.id, text=r.text, label=boolToInt(r.hasMedia))).collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|                id|label|                text|\n",
      "+------------------+-----+--------------------+\n",
      "|668129332066459648|  0.0|e0b40f2381c430f6d...|\n",
      "|668129436932415488|  1.0|:) https://t.co/r...|\n",
      "|668128681945092096|  0.0|برد 😊 (@ miral -...|\n",
      "|668128627406610432|  0.0|christmas market:...|\n",
      "|668128627394019328|  0.0|يا عزيزي يالمدريد...|\n",
      "|668129030068166657|  0.0|#noelgeek #ghostb...|\n",
      "|668129332041265152|  0.0|Soooooo these #ne...|\n",
      "|668128937801682945|  0.0|Green Turtle in W...|\n",
      "|668129025890455552|  0.0|#Retail #Job in #...|\n",
      "|668129269160222720|  0.0|#StaracArabia\n",
      "الن...|\n",
      "|668128677763379201|  0.0|Açlık oyunları al...|\n",
      "|668128749032902656|  0.0|#beaurivagegolf #...|\n",
      "|668129231386333185|  0.0|@bm0406 @ionacrv ...|\n",
      "|668129369819357184|  0.0|#Bilinmezlik @ İz...|\n",
      "|668128673560592384|  0.0|Razón tenía aquel...|\n",
      "|668129055238062081|  0.0|349.336 personas ...|\n",
      "|668128820365512704|  0.0|🎉🎉🎉 @ Quilmes,...|\n",
      "|668129436898885633|  0.0|Risottinho de moq...|\n",
      "|668128317044826113|  0.0|fish bowl fridays...|\n",
      "|668128518354698242|  0.0|Viendo el partido...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "ml_with_words_df = tokenizer.transform(ml_df).drop(\"text\")\n",
    "ml_with_word_df = ml_with_words_df.flatMap(lambda r: [Row(id=r.id,label=r.label,word=w) for w in r.words]).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|                id|label|                word|\n",
      "+------------------+-----+--------------------+\n",
      "|668129332066459648|  0.0|e0b40f2381c430f6d...|\n",
      "|668129436932415488|  1.0|                  :)|\n",
      "|668129436932415488|  1.0|https://t.co/riry...|\n",
      "|668128681945092096|  0.0|                 برد|\n",
      "|668128681945092096|  0.0|                  😊|\n",
      "|668128681945092096|  0.0|                  (@|\n",
      "|668128681945092096|  0.0|               miral|\n",
      "|668128681945092096|  0.0|                   -|\n",
      "|668128681945092096|  0.0|               ميرال|\n",
      "|668128681945092096|  0.0|                  in|\n",
      "|668128681945092096|  0.0|             kuwait)|\n",
      "|668128681945092096|  0.0|https://t.co/yfno...|\n",
      "|668128627406610432|  0.0|           christmas|\n",
      "|668128627406610432|  0.0|             market:|\n",
      "|668128627406610432|  0.0|                that|\n",
      "|668128627406610432|  0.0|                time|\n",
      "|668128627406610432|  0.0|                  of|\n",
      "|668128627406610432|  0.0|                 the|\n",
      "|668128627406610432|  0.0|                year|\n",
      "|668128627406610432|  0.0|               again|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_with_word_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(ml_with_word_df)\n",
    "wordIndexer = StringIndexer(inputCol=\"word\", outputCol=\"indexedWord\").fit(ml_with_word_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "training, test = ml_with_word_df.randomSplit((0.7, 0.3), seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedWord\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[labelIndexer, wordIndexer, dt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column indexedWord must be of type org.apache.spark.mllib.linalg.VectorUDT@f71b0bce but was actually DoubleType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;34m'An error occurred while calling {0}{1}{2}.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     format(target_id, '.', name), value)\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o208.fit.\n: java.lang.IllegalArgumentException: requirement failed: Column indexedWord must be of type org.apache.spark.mllib.linalg.VectorUDT@f71b0bce but was actually DoubleType.\n\tat scala.Predef$.require(Predef.scala:233)\n\tat org.apache.spark.ml.util.SchemaUtils$.checkColumnType(SchemaUtils.scala:42)\n\tat org.apache.spark.ml.PredictorParams$class.validateAndTransformSchema(Predictor.scala:50)\n\tat org.apache.spark.ml.classification.Classifier.org$apache$spark$ml$classification$ClassifierParams$$super$validateAndTransformSchema(Classifier.scala:56)\n\tat org.apache.spark.ml.classification.ClassifierParams$class.validateAndTransformSchema(Classifier.scala:40)\n\tat org.apache.spark.ml.classification.ProbabilisticClassifier.org$apache$spark$ml$classification$ProbabilisticClassifierParams$$super$validateAndTransformSchema(ProbabilisticClassifier.scala:53)\n\tat org.apache.spark.ml.classification.ProbabilisticClassifierParams$class.validateAndTransformSchema(ProbabilisticClassifier.scala:37)\n\tat org.apache.spark.ml.classification.ProbabilisticClassifier.validateAndTransformSchema(ProbabilisticClassifier.scala:53)\n\tat org.apache.spark.ml.Predictor.transformSchema(Predictor.scala:116)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:62)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:89)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:207)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-3e1bebb3926b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml_with_word_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[0;32m--> 538\u001b[0;31m                 self.target_id, self.name)\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Column indexedWord must be of type org.apache.spark.mllib.linalg.VectorUDT@f71b0bce but was actually DoubleType."
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(ml_with_word_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|                id|label|                text|\n",
      "+------------------+-----+--------------------+\n",
      "|668129332066459648|  0.0|e0b40f2381c430f6d...|\n",
      "|668128681945092096|  0.0|برد 😊 (@ miral -...|\n",
      "|668128627406610432|  0.0|christmas market:...|\n",
      "|668129030068166657|  0.0|#noelgeek #ghostb...|\n",
      "|668128937801682945|  0.0|Green Turtle in W...|\n",
      "|668129025890455552|  0.0|#Retail #Job in #...|\n",
      "|668129269160222720|  0.0|#StaracArabia\n",
      "الن...|\n",
      "|668128749032902656|  0.0|#beaurivagegolf #...|\n",
      "|668129231386333185|  0.0|@bm0406 @ionacrv ...|\n",
      "|668129369819357184|  0.0|#Bilinmezlik @ İz...|\n",
      "|668128673560592384|  0.0|Razón tenía aquel...|\n",
      "|668129055238062081|  0.0|349.336 personas ...|\n",
      "|668128820365512704|  0.0|🎉🎉🎉 @ Quilmes,...|\n",
      "|668129436898885633|  0.0|Risottinho de moq...|\n",
      "|668128317044826113|  0.0|fish bowl fridays...|\n",
      "|668128518354698242|  0.0|Viendo el partido...|\n",
      "|667706185517240320|  0.0|Catch The Sooo Se...|\n",
      "|667705011103621120|  0.0|We're #hiring! Cl...|\n",
      "|667705933833834496|  0.0|Old friends thru ...|\n",
      "|667705933825515520|  0.0|I'm at Aydın Fen ...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|                id|label|                text|\n",
      "+------------------+-----+--------------------+\n",
      "|668129436932415488|  1.0|:) https://t.co/r...|\n",
      "|668128627394019328|  0.0|يا عزيزي يالمدريد...|\n",
      "|668129332041265152|  0.0|Soooooo these #ne...|\n",
      "|668128677763379201|  0.0|Açlık oyunları al...|\n",
      "|667705069832306688|  0.0|@PenyukaAnisa wau...|\n",
      "|668130883946188800|  1.0|See a virtual tou...|\n",
      "|668131290781081600|  1.0|HAPPY BIRTHDAY BB...|\n",
      "|668131672475492352|  0.0|I'm at CineRitz f...|\n",
      "|668131018172317697|  0.0|TRAFFIC STOP at S...|\n",
      "|668131919943458817|  0.0|SLS AMG///  😍 @ ...|\n",
      "|668126962271911936|  0.0|Seng ulang tahunn...|\n",
      "|668127545284497408|  0.0|@lndsm101 kkkkk n...|\n",
      "|668380373722660864|  0.0|Mari makan 😋 (at...|\n",
      "|668380608616382464|  0.0|I'm at happy trai...|\n",
      "|668380835104489472|  0.0|Hehe..thx for tod...|\n",
      "|668130045106475010|  0.0|Ver la @premierle...|\n",
      "|668130430961479680|  0.0|• TIME ♡ FLIES •\n",
      "...|\n",
      "|668052060399603713|  0.0|Хорошие зонтики, ...|\n",
      "|668052203018522625|  0.0|See ya omaha. #je...|\n",
      "|668052882478927872|  0.0|Nyam nyam (at @yu...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"id\", \"text\", \"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-----+----------+\n",
      "|                id|                text|label|prediction|\n",
      "+------------------+--------------------+-----+----------+\n",
      "|668129436932415488|:) https://t.co/r...|  1.0|       0.0|\n",
      "|668128627394019328|يا عزيزي يالمدريد...|  0.0|       0.0|\n",
      "|668129332041265152|Soooooo these #ne...|  0.0|       0.0|\n",
      "|668128677763379201|Açlık oyunları al...|  0.0|       0.0|\n",
      "|667705069832306688|@PenyukaAnisa wau...|  0.0|       0.0|\n",
      "|668130883946188800|See a virtual tou...|  1.0|       0.0|\n",
      "|668131290781081600|HAPPY BIRTHDAY BB...|  1.0|       0.0|\n",
      "|668131672475492352|I'm at CineRitz f...|  0.0|       0.0|\n",
      "|668131018172317697|TRAFFIC STOP at S...|  0.0|       0.0|\n",
      "|668131919943458817|SLS AMG///  😍 @ ...|  0.0|       0.0|\n",
      "|668126962271911936|Seng ulang tahunn...|  0.0|       0.0|\n",
      "|668127545284497408|@lndsm101 kkkkk n...|  0.0|       0.0|\n",
      "|668380373722660864|Mari makan 😋 (at...|  0.0|       0.0|\n",
      "|668380608616382464|I'm at happy trai...|  0.0|       0.0|\n",
      "|668380835104489472|Hehe..thx for tod...|  0.0|       0.0|\n",
      "|668130045106475010|Ver la @premierle...|  0.0|       0.0|\n",
      "|668130430961479680|• TIME ♡ FLIES •\n",
      "...|  0.0|       0.0|\n",
      "|668052060399603713|Хорошие зонтики, ...|  0.0|       0.0|\n",
      "|668052203018522625|See ya omaha. #je...|  0.0|       0.0|\n",
      "|668052882478927872|Nyam nyam (at @yu...|  0.0|       0.0|\n",
      "+------------------+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
